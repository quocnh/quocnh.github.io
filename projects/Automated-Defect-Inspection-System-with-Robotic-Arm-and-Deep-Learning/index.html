<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Automated Defect Inspection System with Robotic Arm and Deep Learning | Quoc H. Nguyen </title> <meta name="author" content="Quoc H. Nguyen"> <meta name="description" content="Developed an automated defect inspection system using a robotic arm, computer vision, and deep learning to efficiently detect and classify product defects on a conveyor belt."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://quocnh.github.io/projects/Automated-Defect-Inspection-System-with-Robotic-Arm-and-Deep-Learning/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Quoc</span> H. Nguyen </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Automated Defect Inspection System with Robotic Arm and Deep Learning</h1> <p class="post-description">Developed an automated defect inspection system using a robotic arm, computer vision, and deep learning to efficiently detect and classify product defects on a conveyor belt.</p> </header> <article> <h1 id="robot-arm-in-product-inspection-with-ros-and-deep-learning">Robot Arm in product inspection with ROS and Deep Learning.</h1> <p>This is a brief note about the way we built a simple Robot Arm and Deep Leanring approach in order to make a model to predict defects in product inspection.</p> <h1 id="video-link">Video link:</h1> <ol> <li>https://drive.google.com/file/d/1KCF31cqWTbForki-6d7YNfTgb_rOv_WZ/view?usp=sharing</li> <li>https://drive.google.com/file/d/1sIMJ3BOCjd-B2ghHndZeDxoD2xsCqL9v/view?usp=sharing</li> <li>Github Source: https://github.com/quocnh/RobotArm/tree/master</li> </ol> <h2 id="table-of-contents">Table of Contents</h2> <ul> <li><a href="#">1. Introduction</a></li> <li><a href="#1.-system-overview">2. System Overview</a></li> <li> <a href="#">3. Controlling the Robot Arm by ROS</a> <ul> <li><a href="#">3.1 ROS</a></li> <li> <a href="#">3.2 Design the Arm</a> <ul> <li><a href="#">Generalized Coordinates</a></li> <li><a href="#">Degrees of Freedom</a></li> <li><a href="#">Robot Kinematics</a></li> <li> <a href="#">Forward Kinematics</a> <ul> <li><a href="#">Calculating Homodeneous Transformation Matrix</a></li> </ul> </li> <li><a href="#">Invert Kinematics</a></li> <li> <a href="#">Visualizing the Arm in Rviz</a> <ul> <li><a href="#">URDF</a></li> </ul> </li> <li><a href="#">Motion plaining with MoveIt</a></li> </ul> </li> <li><a href="#">3.3 Communication between of the Arm and Raspberry Pi by ROS </a></li> </ul> </li> <li> <a href="#">4. Creating a Deep Learning Model</a> <ul> <li><a href="#">4.1 Preparing data</a></li> <li><a href="#">4.2 Training with RESNET-50</a></li> </ul> </li> <li> <a href="#">5. Capturing Objects by Pi Camera</a> <ul> <li><a href="#">5.1 Connecting Pi Camera to the Arm</a></li> <li><a href="#">5.2 Making Pi Camera Server</a></li> </ul> </li> <li> <a href="#">6. Implementation and Experimental Reslut </a> <ul> <li><a href="#">6.1 Kinametic Implementation</a></li> <li><a href="#">6.2 The Robot Arm performance</a></li> <li><a href="#">6.3 Prediction Result</a></li> </ul> </li> <li><a href="#">7. Conclusion</a></li> <li><a href="#">8. References</a></li> </ul> <h2 id="abbreviations">Abbreviations</h2> <ul> <li>DOF Degrees Of Freedom</li> <li>ROS Robot Operating System</li> <li>ARC Amazon Robotics Challenge</li> <li>ISS International Space Station</li> <li>EVA Extra Vehicular Activity</li> <li>EE End-Effector</li> <li>WC Wrist Center</li> <li>DH Denavit–Hartenberg</li> <li>FK Forward Kinematics</li> <li>IK Inverse Kinematics</li> <li>RRR Revolute Revolute Revolute</li> <li>URDF Unified Robot Description Format</li> </ul> <h2 id="1-introduction">1. Introduction</h2> <p>This project explores the development of an automated inspection system designed to detect defects in products on a conveyor belt, replacing traditional manual inspection methods. In many factories, human operators manually inspect products and remove defective ones, which is labor-intensive and prone to inconsistency. By introducing a robotic arm combined with deep learning, this project demonstrates a system capable of efficiently identifying and handling defective products with high accuracy.</p> <p>The proposed system integrates a robotic arm controlled via the Robot Operating System (ROS) and a deep learning model to detect even the smallest defects in products. This approach offers significant improvements in speed, reliability, and scalability compared to manual inspection. The project outlines the construction of the robotic arm, the implementation of ROS for motion planning, and the development of a deep learning model trained to identify defects with precision. Together, these components create a promising foundation for fully automated product inspection processe.</p> <h2 id="2-system-overview">2. System Overview</h2> <p align="center"> <img src="https://github.com/quocnh/RobotArm/blob/master/assert/overall_system.png" alt="" width="65%"> <br> <sup><b>Fig1.0    Overall System</b></sup> <br> </p> <p>The Figure 1 shows the overall system of the process of product inspection, which including three main parts: (1) Controlling the Robot Arm by ROS; (2) Capturing photos of product and (3) Deep Learning model. We will explain each part in detail bellow:</p> <h2 id="3-controlling-the-robot-arm-by-ros">3. Controlling the Robot Arm By ROS</h2> <h3 id="31-robot-operate-system">3.1 Robot Operate System</h3> <p>ROS is an open-source, meta-operating system for your robot. It provides the services you would expect from an operating system, including hardware abstraction, low-level device control, implementation of commonly-used functionality, message-passing between processes, and package management. It also provides tools and libraries for obtaining, building, writing, and running code across multiple computers. [6]</p> <p>The ROS Wiki defines ROS as above. In other words, ROS includes hardware abstraction layer similar to operating systems. However, unlike conventional operating systems, it can be used for numerous combinations of hardware implementation. Furthermore, it is a robot software platform that provides various development environments specialized for developing robot application programs.</p> <h3 id="32-design-the-arm">3.2 Design the Arm</h3> <p>The following theoretical concepts are used in this project:</p> <ul> <li>Generalized Coordinates and Degrees of Freedom</li> <li>Rotation matrices and composition of rotations</li> <li>Homogeneous transforms</li> <li>Denavit–Hartenberg parameters</li> <li>Forward and Inverse Kinematics</li> </ul> <p>And the following tools are used for simulation and motion planning:</p> <p>The project uses <a href="http://wiki.ros.org/kinetic" rel="external nofollow noopener" target="_blank">ROS Kinetic Kame</a> running on <a href="http://releases.ubuntu.com/16.04/" rel="external nofollow noopener" target="_blank">Ubuntu 16.04 LTS (Xenial Xerus)</a>.</p> <ul> <li> <a href="http://gazebosim.org/" rel="external nofollow noopener" target="_blank">Gazebo</a>: a physics based 3D simulator extensively used in the robotics world</li> <li> <a href="http://wiki.ros.org/rviz" rel="external nofollow noopener" target="_blank">RViz</a>: a 3D visualizer for sensor data analysis, and robot state visualization</li> <li> <a href="http://moveit.ros.org/" rel="external nofollow noopener" target="_blank">MoveIt!</a>: a ROS based software framework for motion planning, kinematics and robot control</li> </ul> <h4 id="generalized-coordinates">Generalized Coordinates</h4> <p>Generalized coordinates are parameters that are used to uniquely describe the instantaneous dynamical configuration of a <a href="https://en.wikipedia.org/wiki/Rigid_body" rel="external nofollow noopener" target="_blank">rigid</a> <a href="https://en.wikipedia.org/wiki/Multibody_system" rel="external nofollow noopener" target="_blank">multi-body system</a> relative to some reference configuration. In the robotics of serial manipulators, they are used to define the <em>configuration space</em> or <em>joint space</em>, which refers to the set of all possible configurations a manipulator may have.</p> <h4 id="degrees-of-freedom">Degrees of Freedom</h4> <p>The <a href="https://en.wikipedia.org/wiki/Degrees_of_freedom_(mechanics)" rel="external nofollow noopener" target="_blank">degree of freedom (DOF)</a> of a rigid body or mechanical system is the number of independent parameters or coordinates that fully define its configuration in free space.</p> <h4 id="321-robot-kinematics">3.2.1 Robot Kinematics</h4> <p>Robot kinematics applies geometry to the study of the movement of multi-degree of freedom kinematic chains that form the structure of robotic systems. A fundamental tool in robot kinematics is the kinematics equations of the kinematic chains that form the robot. These non-linear equations are used to map the joint parameters to the configuration of the robot system.</p> <p>“Robot Arm” = Joints + Links. Speciffically, Joints are parts that allow motion (in our case, Joints are 6 servos) and Links are parts that connect Joints together.</p> <p>a. Kinematic Diagram Diagram that shows how the links and joints are connected together, when all of the joints variables have a value of 0. There are some crucial rules:</p> <ul> <li>Rule 1: The Z axis must be the axis of rotation for a revolute joint, ot the direction of motion for a prismatic joint.</li> <li>Rule 2: The X axis must be perpendicular both to its own Z axis, and the Z axis of the frame before it.</li> <li>Rule 3: All frames must follow the right-hand rule.</li> <li> <p>Rule 4: Each X axis must intersect the Z axis of the frame before it.</p> </li> <li>There are 6 DoFs but we only need 5 DoFs, follow 4 rules above we got the kinematic diagram:</li> </ul> <p><img src="assert/kinematic_diagram1.jpeg" width="700" title="DH diagram"></p> <h4 id="forward-kinematics">Forward Kinematics</h4> <p>Forward kinematics specifies the joint parameters and computes the configuration of the chain, following these steps below:</p> <h5 id="calculating-homodeneous-transformation-matrix">Calculating Homodeneous Transformation Matrix</h5> <p>In detail, there are 2 methods to compute the HTM:</p> <h6 id="method-1-basic">Method 1 (Basic):</h6> <p>First, finding the rotation matrix and the displacement vector for each pair of subsequent frames and then assembling those two components together into the homogeneous transformation matrix.</p> <ul> <li> <p>Calculating Rotation Matrices <img src="assert/rotation_fomular.png" width="300" title="DH diagram"></p> </li> <li> <p>Calculating Displacement Vectors <img src="assert/displacement_vector.png" width="300" title="DH diagram"></p> </li> </ul> <p>The displacement vetor only has one column and it has 3 rows. The first row tells us the x position of the n frame in the m frame. The 2nd row tells us the Y position and the 3rd row tells us the Z posiiton.</p> <ul> <li>Assembling Rotation matrices and Displacement Vectors into Homogeneous Transformation Matrix:</li> </ul> <h6 id="method-2-denavit-hartenberg">Method 2 (Denavit Hartenberg):</h6> <p>In mechanical engineering, the Denavit–Hartenberg parameters (also called DH parameters) are the four parameters associated with a particular convention for attaching reference frames to the links of a spatial kinematic chain, or robot manipulator. It is a kind of industry standard that we’ll frequently see in robotics research papers and industry documentation.</p> <p>This method is faster than the other way but it kind of obscures the meaning behind the rotation matrix and the displacement vector. So it is important to fist do the basic method above and make sure we understand the meaning of each part of the homogeneous transformation before we srat taking the shorcut method to the end.</p> <p><img src="assert/Classic-DHparameters.png" alt="viewer"></p> <p>The following 4 transformation parameters are known as D–H parameters:</p> <ul> <li>d - the distance between the previous x-axis and the current x-axis, along the previous z-axis.</li> <li>θ - the angle around the z-axis between the previous x-axis and current x-axis.</li> <li>a (or r) - the length of the common normal, which is the distance between the previous z-axis and the current z-axis.</li> <li> <p>α - the angle around the common normal to between the previous z-axis and current z-axis.</p> </li> <li>Step 1: Assign frames according to the 4 Denavit-Hartenberg rules.</li> <li>Step 2: Fill out the Denavit-Hartenberg parameter table.</li> <li>Step 3: Get the Homogeneous transformation matrix</li> </ul> <p><img src="assert/DH_fomular.png" width="500" title="DH Fomular"></p> <h4 id="invert-kinematics">Invert Kinematics</h4> <p>Inverse kinematics specifies the end-effector location and computes the associated joint angles. The inverse kinematics problem of the serial manipulators has been studied for many decades. It is needed in the control of manipulators. Solving the inverse kinematics is computationally expansive and generally takes a very long time in the real time control of manipulators. Tasks to be performed by a manipulator are in the Cartesian space, whereas actuators work in joint space. Cartesian space includes orientation matrix and position vector. However, joint space is represented by joint angles. The conversion of the position and orientation of a manipulator end-effector from Cartesian space to joint space is called as inverse kinematics problem.</p> <p>The implementation of Forward and Invert Kinematic is shown in the colab file at the portion of 6.1 Kinematic Implementation.</p> <h4 id="visualizing-the-arm-in-rviz">Visualizing the Arm in Rviz</h4> <p>To simulate a Robot Arm model in virtual space, first we need to create a URDF for the Arm consisting of joints and links.</p> <p>URDF describes each component of the robot using XML tags. In the URDF format, first describe the name of the robot, the name and type of the base (URDF assumes that the base is a fixed link), and the description of the link connected to the base and then describe each joint and link. A link describes the name, size, weight, inertia of the link. The joints describes the name, type, and link connected to each joint. The dynamic parameters of the robot, visualization, and the collision model can be easily set. The URDF is initiated by the <robot> tag, and in general, it is common for the <link> tag and the <joint> tag to appear alternately to define links and joints that are components of the robot. The <transmission> tag is also often included for interfacing with the ROS-Control to establish the relationship between the joint and the actuator. Let’s take a closer look at the robot.urdf we created.</transmission></joint></robot></p> <p>Robot.urdf</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;?xml <span class="nv">version</span><span class="o">=</span><span class="s2">"1.0"</span>?&gt;
&lt;robot <span class="nv">name</span><span class="o">=</span><span class="s2">"myfirst"</span><span class="o">&gt;</span>
  &lt;material <span class="nv">name</span><span class="o">=</span><span class="s2">"blue"</span><span class="o">&gt;</span>
    &lt;color <span class="nv">rgba</span><span class="o">=</span><span class="s2">"0 0 0.8 1"</span>/&gt;
  &lt;/material&gt;
  &lt;<span class="nb">link </span><span class="nv">name</span><span class="o">=</span><span class="s2">"base_link"</span><span class="o">&gt;</span>
    &lt;visual&gt;
      &lt;origin
        <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0 0 0"</span>
        <span class="nv">rpy</span><span class="o">=</span><span class="s2">"0 0 0"</span> /&gt;
      &lt;geometry&gt;
        &lt;box <span class="nv">size</span><span class="o">=</span><span class="s2">"0.6 0.1 0.02"</span>/&gt;
      &lt;/geometry&gt;
    &lt;/visual&gt;
  &lt;/link&gt;

  &lt;<span class="nb">link </span><span class="nv">name</span><span class="o">=</span><span class="s2">"link_0"</span><span class="o">&gt;</span>
    &lt;visual&gt;
      &lt;geometry&gt;
        &lt;cylinder <span class="nv">length</span><span class="o">=</span><span class="s2">"0.1"</span> <span class="nv">radius</span><span class="o">=</span><span class="s2">"0.05"</span>/&gt;
      &lt;/geometry&gt;
      &lt;origin <span class="nv">rpy</span><span class="o">=</span><span class="s2">"0 0 0.02"</span> <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0 0 0.05"</span>/&gt;
    &lt;/visual&gt;
  &lt;/link&gt;


  &lt;joint <span class="nv">name</span><span class="o">=</span><span class="s2">"joint_1"</span> <span class="nb">type</span><span class="o">=</span><span class="s2">"revolute"</span><span class="o">&gt;</span>
    &lt;axis <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0 0 1"</span>/&gt;
    &lt;limit <span class="nv">effort</span><span class="o">=</span><span class="s2">"1000.0"</span> <span class="nv">lower</span><span class="o">=</span><span class="s2">"-1.0"</span> <span class="nv">upper</span><span class="o">=</span><span class="s2">"1.0"</span> <span class="nv">velocity</span><span class="o">=</span><span class="s2">"0.5"</span>/&gt;
    &lt;parent <span class="nb">link</span><span class="o">=</span><span class="s2">"base_link"</span>/&gt;
    &lt;child <span class="nb">link</span><span class="o">=</span><span class="s2">"link_0"</span>/&gt;
    &lt;origin <span class="nv">rpy</span><span class="o">=</span><span class="s2">"0 0 0"</span> <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0 0 0.01"</span>/&gt;
  &lt;/joint&gt;

  &lt;<span class="nb">link </span><span class="nv">name</span><span class="o">=</span><span class="s2">"link_1"</span><span class="o">&gt;</span>
    &lt;visual&gt;
      &lt;geometry&gt;
        &lt;box <span class="nv">size</span><span class="o">=</span><span class="s2">"0.2 0.1 0.02"</span>/&gt;
      &lt;/geometry&gt;
      &lt;origin <span class="nv">rpy</span><span class="o">=</span><span class="s2">"0 1.57075 0"</span> <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0 0 0.1"</span>/&gt;
    &lt;/visual&gt;
  &lt;/link&gt;

  &lt;joint <span class="nv">name</span><span class="o">=</span><span class="s2">"joint_2"</span> <span class="nb">type</span><span class="o">=</span><span class="s2">"revolute"</span><span class="o">&gt;</span>
    &lt;axis <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0 1 0"</span>/&gt;
    &lt;limit <span class="nv">effort</span><span class="o">=</span><span class="s2">"1000.0"</span> <span class="nv">lower</span><span class="o">=</span><span class="s2">"0.0"</span> <span class="nv">upper</span><span class="o">=</span><span class="s2">"1.0"</span> <span class="nv">velocity</span><span class="o">=</span><span class="s2">"0.5"</span>/&gt;
    &lt;parent <span class="nb">link</span><span class="o">=</span><span class="s2">"link_0"</span>/&gt;
    &lt;child <span class="nb">link</span><span class="o">=</span><span class="s2">"link_1"</span>/&gt;
    &lt;origin <span class="nv">rpy</span><span class="o">=</span><span class="s2">"0 0 0"</span> <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0 0 0.1"</span>/&gt;
  &lt;/joint&gt;

  &lt;<span class="nb">link </span><span class="nv">name</span><span class="o">=</span><span class="s2">"link_2"</span><span class="o">&gt;</span>
    &lt;visual&gt;
      &lt;geometry&gt;
        &lt;box <span class="nv">size</span><span class="o">=</span><span class="s2">"0.2 0.1 0.02"</span>/&gt;
      &lt;/geometry&gt;
      &lt;origin <span class="nv">rpy</span><span class="o">=</span><span class="s2">"0 2.1075 0"</span> <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0.05 0 0.08"</span>/&gt;
    &lt;/visual&gt;
  &lt;/link&gt;

  &lt;joint <span class="nv">name</span><span class="o">=</span><span class="s2">"joint_3"</span> <span class="nb">type</span><span class="o">=</span><span class="s2">"revolute"</span><span class="o">&gt;</span>
    &lt;axis <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0 1 0"</span>/&gt;
    &lt;limit <span class="nv">effort</span><span class="o">=</span><span class="s2">"1000.0"</span> <span class="nv">lower</span><span class="o">=</span><span class="s2">"0.0"</span> <span class="nv">upper</span><span class="o">=</span><span class="s2">"1.0"</span> <span class="nv">velocity</span><span class="o">=</span><span class="s2">"0.5"</span>/&gt;
    &lt;parent <span class="nb">link</span><span class="o">=</span><span class="s2">"link_1"</span>/&gt;
    &lt;child <span class="nb">link</span><span class="o">=</span><span class="s2">"link_2"</span>/&gt;
    &lt;origin <span class="nv">rpy</span><span class="o">=</span><span class="s2">"0 0 0"</span> <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0 0 0.2"</span>/&gt;
  &lt;/joint&gt;

  &lt;<span class="nb">link </span><span class="nv">name</span><span class="o">=</span><span class="s2">"link_3"</span><span class="o">&gt;</span>
    &lt;visual&gt;
      &lt;geometry&gt;
        &lt;box <span class="nv">size</span><span class="o">=</span><span class="s2">"0.1 0.1 0.02"</span>/&gt;
      &lt;/geometry&gt;
      &lt;origin <span class="nv">rpy</span><span class="o">=</span><span class="s2">"0 3.1075 0"</span> <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0.05 0 0"</span>/&gt;
    &lt;/visual&gt;
  &lt;/link&gt;

  &lt;joint <span class="nv">name</span><span class="o">=</span><span class="s2">"joint_4"</span> <span class="nb">type</span><span class="o">=</span><span class="s2">"revolute"</span><span class="o">&gt;</span>
    &lt;axis <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0 1 0"</span>/&gt;
    &lt;limit <span class="nv">effort</span><span class="o">=</span><span class="s2">"1000.0"</span> <span class="nv">lower</span><span class="o">=</span><span class="s2">"0.0"</span> <span class="nv">upper</span><span class="o">=</span><span class="s2">"1.0"</span> <span class="nv">velocity</span><span class="o">=</span><span class="s2">"0.5"</span>/&gt;
    &lt;parent <span class="nb">link</span><span class="o">=</span><span class="s2">"link_2"</span>/&gt;
    &lt;child <span class="nb">link</span><span class="o">=</span><span class="s2">"link_3"</span>/&gt;
    &lt;origin <span class="nv">rpy</span><span class="o">=</span><span class="s2">"0 0 0"</span> <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0.11 0 0.16"</span>/&gt;
  &lt;/joint&gt;

  &lt;<span class="nb">link </span><span class="nv">name</span><span class="o">=</span><span class="s2">"wheel_gripper"</span><span class="o">&gt;</span>
    &lt;visual&gt;
      &lt;geometry&gt;
        &lt;cylinder <span class="nv">length</span><span class="o">=</span><span class="s2">"0.02"</span> <span class="nv">radius</span><span class="o">=</span><span class="s2">"0.02"</span>/&gt;
      &lt;/geometry&gt;
      &lt;origin <span class="nv">rpy</span><span class="o">=</span><span class="s2">"0 1.57075 0"</span> <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0.01 0 0"</span>/&gt;
    &lt;/visual&gt;
  &lt;/link&gt;

  &lt;joint <span class="nv">name</span><span class="o">=</span><span class="s2">"joint_5"</span> <span class="nb">type</span><span class="o">=</span><span class="s2">"revolute"</span><span class="o">&gt;</span>
    &lt;axis <span class="nv">xyz</span><span class="o">=</span><span class="s2">"1 0 0"</span>/&gt;
    &lt;limit <span class="nv">effort</span><span class="o">=</span><span class="s2">"1000.0"</span> <span class="nv">lower</span><span class="o">=</span><span class="s2">"0.0"</span> <span class="nv">upper</span><span class="o">=</span><span class="s2">"1.0"</span> <span class="nv">velocity</span><span class="o">=</span><span class="s2">"0.5"</span>/&gt;
    &lt;parent <span class="nb">link</span><span class="o">=</span><span class="s2">"link_3"</span>/&gt;
    &lt;child <span class="nb">link</span><span class="o">=</span><span class="s2">"wheel_gripper"</span>/&gt;
    &lt;origin <span class="nv">rpy</span><span class="o">=</span><span class="s2">"0 0 0"</span> <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0.1 0 0"</span>/&gt;
  &lt;/joint&gt;

  &lt;<span class="nb">link </span><span class="nv">name</span><span class="o">=</span><span class="s2">"gripper"</span><span class="o">&gt;</span>
    &lt;visual&gt;
      &lt;geometry&gt;
        &lt;cylinder <span class="nv">length</span><span class="o">=</span><span class="s2">"0.05"</span> <span class="nv">radius</span><span class="o">=</span><span class="s2">"0.01"</span>/&gt;
      &lt;/geometry&gt;
      &lt;origin <span class="nv">rpy</span><span class="o">=</span><span class="s2">"0 1.57075 0"</span> <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0.025 0 0"</span>/&gt;
      &lt;material <span class="nv">name</span><span class="o">=</span><span class="s2">"blue"</span>/&gt;
    &lt;/visual&gt;
  &lt;/link&gt;

  &lt;joint <span class="nv">name</span><span class="o">=</span><span class="s2">"wheel_gripper_to_gripper"</span> <span class="nb">type</span><span class="o">=</span><span class="s2">"fixed"</span><span class="o">&gt;</span>
    &lt;parent <span class="nb">link</span><span class="o">=</span><span class="s2">"wheel_gripper"</span>/&gt;
    &lt;child <span class="nb">link</span><span class="o">=</span><span class="s2">"gripper"</span>/&gt;
    &lt;origin <span class="nv">rpy</span><span class="o">=</span><span class="s2">"0 0 0"</span> <span class="nv">xyz</span><span class="o">=</span><span class="s2">"0.02 0 0"</span>/&gt;
  &lt;/joint&gt;


&lt;/robot&gt;

</code></pre></div></div> <p>After created a URDF for our robot model, next we display and interac with the robot model by using Rviz. RViz is the 3D visualization tool of ROS. It supports various visualization using user specified polygons, and Interactive Markers allow users to perform interactive movements with commands and data received from the user node. In addition, ROS describes robots in Unified Robot Description Format (URDF), which is expressed as a 3D model for which each model can be moved or operated according to their corresponding degree of freedom, so they can be used for simulation or control.</p> <p>The robot model can be displayed and interacted as shown in Figure bellow.</p> <p><img src="assert/moveit.png" width="500" title="Moveit"></p> <h4 id="motion-plaining-with-moveit">Motion plaining with MoveIt</h4> <p>The motion planning, which is also called as path planning, creates a trajectory from the current pose to the target pose specified on the map. The created path plan includes the global path planning in the whole map and the local path planning for smaller areas around the robot. We plan to use the OMPL algorithm to optimize the trajactory of the Arm. OMPL can be install by Moveit Assistant Wizard, more information can found in the index page at http://ompl.kavrakilab.org/</p> <h3 id="33-communication-between-of-the-arm-and-raspberry-pi-by-ros">3.3 Communication between of the Arm and Raspberry Pi by ROS</h3> <p><img src="assert/rosgraph.png" width="500" title="ros_graph"></p> <p>ROS is developed in unit of nodes, which is the minimum unit of executetable program that has broken down for the maximum reusability. The node exchanges data with other nodes through messages forming a large program as a whole. The key concept here is the message communication methods among nodes. There are three different methods of exchanging messages: a topic which prodives a unidirectional messafe transmission/reception, a service which provides a bidirectional messafe request/response and an action which provides a bidirectional message goal/result/feedback. In addition, the parameters used in the node can be modified from the outside of node. This can also be considered as a type of message communication in the larger context. Message communication is illustrated and the differences are summarized in the Figure and Table bellow . It is important to use each topic, service, action, and parameter according to its correct purpose when programming on ROS.</p> <p><img src="assert/ros_communication.png" width="500" title="ros_graph"></p> <p><img src="assert/communication_table.png" width="500" title="ros_graph"></p> <h2 id="4-creating-a-deep-learning-model">4. Creating a Deep Learning Model</h2> <h3 id="41-preparing-data">4.1 Preparing data</h3> <p>To efficiently prepare the dataset, a custom C++ program was developed to extract frames from video recordings. This approach significantly reduced the time and effort required for object data collection, as it automated the process of capturing high-quality images of the inspected objects. Using computer vision techniques, the program ensured accurate frame extraction while maintaining image quality for subsequent processing.</p> <p>The captured frames were then pre-processed and labeled to serve as input for a deep learning model. This streamlined workflow demonstrates expertise in C++ programming for high-performance tasks, the application of computer vision for automation, and the integration of deep learning to solve real-world challenges in defect detection.</p> <p>Apple (an object) was planted in the shaft of a low speed motor (3 rpm) and a short movie of 20 seconds was recorded. Behind the fruits we placed a white sheet of paper as background.However due to the variations in the lighting conditions, the background was not uniform and we wrote a dedicated algorithm which extract the fruit from the background. This algorithm is of flood fill type: Start from each edge of the image and marking all pixels there, then marking all pixels found in the neighborhood of the already marked pixels for which the distance between colors is less than a prescribed value. Finally, repeat the previous step until no more pixels can be marked. The process like this video https://vimeo.com/286843424</p> <h3 id="42-training-with-resnet-50">4.2 Training with RESNET-50</h3> <p>We defined train &amp; test datasets followed by four metrics above (500 OK and 500 NG images):</p> <h4 id="folder-structure">Folder structure</h4> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Dataset
        |__train
        |    |__OK (400)
        |    |__NG (400)
        |       |__...
        |       |__...
        |
        |__test
            |__OK (100)
            |__NG (100)
                |__...
                |__...
</code></pre></div></div> <h4 id="metrics">Metrics</h4> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>* binary_crossentropy
</code></pre></div></div> <h1 id="5-capturing-objects-by-pi-camera">5. Capturing Objects by Pi Camera</h1> <h3 id="51-connecting-pi-camera-to-the-arm">5.1 Connecting Pi Camera to the Arm</h3> <p>First, connecting the Camera Module to the Raspberry Pi’s camera port, then start up the Pi and ensure the software is enabled. <img src="assert/connect-camera.jpg" width="500" title="ros_graph"></p> <p>Then, we attached the pi camera on top of the Arm. The result like the photo below.</p> <p><img src="assert/pi.JPG" width="500" title="ros_graph"></p> <h3 id="52-making-pi-camera-server">5.2 Making Pi Camera Server</h3> <p>To install camera node in ROS is a tough step. It took alots of time to accomplish. Folow this tutorial to finish this step.</p> <p>In order to use the Raspberry Pi 3 camera v2, we need to install a third-party ROS node from source, since it is not part of the ROS distribution at the moment. The installation is not that straightforward using only the barebones ROS installation, since there are a few dependencies on other packages. Looking at the package definition package.xml, we see the following dependencies:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>catkin
compressed_image_transport
roscpp
std_msgs
std_srvs
sensor_msgs
camera_info_manager
dynamic_reconfigure
libraspberrypi0
</code></pre></div></div> <p>The highlighted ones are missing from the ros_comm stack, so we need to install them manually. The approach here is simply to fetch the missing packages and then merge them into the existing barebones catkin workspace. Lastly, we build and test raspicam_node.</p> <ol> <li>Install all dependencies Fetch the package information for all the missing packages and their ROS dependencies:</li> </ol> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rosinstall_generator compressed_image_transport <span class="nt">--rosdistro</span> kinetic <span class="nt">--deps</span> <span class="nt">--wet-only</span> <span class="nt">--tar</span> <span class="o">&gt;</span> kinetic-compressed_image_transport-wet.rosinstall

rosinstall_generator camera_info_manager <span class="nt">--rosdistro</span> kinetic <span class="nt">--deps</span> <span class="nt">--wet-only</span> <span class="nt">--tar</span> <span class="o">&gt;</span> kinetic-camera_info_manager-wet.rosinstall

rosinstall_generator dynamic_reconfigure <span class="nt">--rosdistro</span> kinetic <span class="nt">--deps</span> <span class="nt">--wet-only</span> <span class="nt">--tar</span> <span class="o">&gt;</span> kinetic-dynamic_reconfigure-wet.rosinstall
</code></pre></div></div> <p>Now we need to fetch the sources and put them to the ~/ros_catkin_ws/src where all the other packages from the barebone installation are located:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wstool merge <span class="nt">-t</span> src kinetic-compressed_image_transport-wet.rosinstall
wstool merge <span class="nt">-t</span> src kinetic-camera_info_manager-wet.rosinstall
wstool merge <span class="nt">-t</span> src kinetic-dynamic_reconfigure-wet.rosinstall
wstool update <span class="nt">-t</span> src
</code></pre></div></div> <p>Fetch any additional Raspbian libraries that are needed</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rosdep <span class="nb">install</span> <span class="nt">--from-paths</span> src <span class="nt">--ignore-src</span> <span class="nt">--rosdistro</span> kinetic <span class="nt">-y</span>
</code></pre></div></div> <p>Build the packages. Please, note that this takes a very long time, so it might be a good idea to build it overnight in a tmux window.</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./src/catkin/bin/catkin_make_isolated <span class="nt">-j1</span> <span class="nt">--install</span> <span class="nt">--install-space</span> /opt/ros/kinetic <span class="nt">-DCMAKE_BUILD_TYPE</span><span class="o">=</span>Release
</code></pre></div></div> <p>It turns out that raspicam_node depends on the raspberry pi library, so we also install the headers:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install </span>libraspberrypi-dev
</code></pre></div></div> <ol> <li>Build the raspicam node Check out the source code for raspicam_node from Github in the workspace src directory: <div class="language-sh highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/ros_catkin_ws
git clone https://github.com/UbiquityRobotics/raspicam_node.git
</code></pre></div> </div> <p>Install other library dependencies automatically:</p> <div class="language-sh highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>rosdep <span class="nb">install</span> <span class="nt">--from-paths</span> src <span class="nt">--ignore-src</span> <span class="nt">--rosdistro</span> kinetic <span class="nt">-y</span>
</code></pre></div> </div> <p>Finally, build and install raspicam_node. It should be possible to do this more specifically with –pkg raspicam and save some time, but this hasn’t been tried yet. Two compilation processes -j2 are a safe option here:</p> <div class="language-sh highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>./src/catkin/bin/catkin_make_isolated <span class="nt">-j2</span> <span class="nt">--install</span> <span class="nt">--install-space</span> /opt/ros/kinetic <span class="nt">-DCMAKE_BUILD_TYPE</span><span class="o">=</span>Release
</code></pre></div> </div> </li> <li>Test the camera Now that we have the camera node installed, we can test the Raspberry camera if we haven’t done that yet. It needs to be enabled with raspi-config from the interface menu: <div class="language-sh highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>raspi-config
</code></pre></div> </div> <p>Take a test shot</p> <div class="language-sh highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>raspistill <span class="nt">-o</span> test.jpg
</code></pre></div> </div> <p>Everything is fine, so we can test the raspicam node.</p> </li> <li>Test raspicam_node Start a new tmux session and source the setup file in every relevant window <div class="language-sh highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="nb">source</span> /opt/ros/kinetic/setup.bash
</code></pre></div> </div> <p>Open a new window for roscore and start it there. Find the launch definitions in ~/ros_catkin_ws/src/raspicam_node/launch/ and go there:</p> <div class="language-sh highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> ~/ros_catkin_ws/src/raspicam_node/launch/
</code></pre></div> </div> <p>Start raspicam_node with the launch configuration of choice:</p> <div class="language-sh highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>roslaunch camerav2_1280x960.launch
</code></pre></div> </div> <p>A simple topic check shows us that the node is active:</p> <div class="language-sh highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>:~<span class="nv">$ </span>rostopic list
/raspicam_node/camera_info
/raspicam_node/image/compressed
/raspicam_node/parameter_descriptions
/raspicam_node/parameter_updates
/rosout
/rosout_agg
</code></pre></div> </div> </li> </ol> <h2 id="6-experimental-reslut">6. Experimental Reslut</h2> <h3 id="61-kinametic-implementation">6.1 Kinametic Implementation</h3> <p>https://colab.research.google.com/drive/16oZtyKOfklekXpCMOa6KYnGSpCuyhuNP</p> <h3 id="62-the-robot-arm-performance">6.2 The Robot Arm performance</h3> <p>(TODO)</p> <h3 id="63-prediction-result">6.3 Prediction Result</h3> <p>Please check the video on top of the paper.</p> <h2 id="7-conclusion">7. Conclusion</h2> <p>This project aims to build a small system that presents the real process in factories. By using a robot arm, image data is collected and deliveried to detect defects. Plus, based on computer vision is out-of-date and imposiible for inspect kind of this problems. Thus, with Deep Leaning, we can train and make a model that can solve the problem. This opens many great ideas follow by such as pick and place object by using deep learning, or categorize object, etc… Or connect the Robot Arm to the conveyor belt for many different purposes.</p> <h2 id="references">References</h2> <ul> <li>[1] Hartenberg parameters, https://en.wikipedia.org/wiki/Denavit%E2%80%93Hartenberg_parameters</li> <li>[2] Publish image stream by raspberry pi, http://www.theconstructsim.com/publish-image-stream-ros-kinetic-raspberry-pi/</li> <li>[3] Videos about AR2 robot, https://www.youtube.com/watch?v=FIx6olybAeQ&amp;feature=youtu.be</li> <li>[4] Robotic course, https://www.youtube.com/playlist?list=PLRG6WP3c31_U7TFGduEIJWVtkOw6AJjFf</li> <li>[5] Forward Kinematic, https://www.youtube.com/watch?v=NRgNDlVtmz0</li> <li>[6] ROS, http://www.ros.org/</li> <li>[7] Setup Pi camera and Raspberry Pi, https://projects.raspberrypi.org/en/projects/getting-started-with-picamera/4</li> <li>[8] Camera node in ROS, https://venelinpetkov.com/2017/11/19/how-to-install-a-raspberry-camera-node-on-ros-kinetic-raspbian-stretch/</li> <li>[9] Interact MoveIt and Industry Robot, https://github.com/eYSIP-2017/eYSIP-2017_Robotic_Arm/wiki/Interfacing-Real-Robot-with-MoveIt!</li> <li>[10] Pick and place, https://groups.google.com/forum/#!topic/moveit-users/_M0mf-R7AvI</li> </ul> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Quoc H. Nguyen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-teaching",title:"teaching",description:"",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"post-206-reverse-linked-list",title:"206. Reverse Linked List",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/leetcode-Reverse-Linked-List/"}},{id:"post-2130-maximum-twin-sum-of-a-linked-list",title:"2130. Maximum Twin Sum of a Linked List",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/leetcode-Maximum-Twin-Sum-of-a-Linked-List/"}},{id:"post-python-data-structures",title:"Python Data Structures",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/python-data-structure-note/"}},{id:"post-392-is-subsequence",title:"392. Is Subsequence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/leetcode-is-subsequences/"}},{id:"post-238-product-of-array-except-self",title:"238. Product of Array Except Self",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/leetcode-product-of-array-except-self/"}},{id:"post-334-increasing-triplet-subsequence",title:"334. Increasing Triplet Subsequence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/leetcode-increasing-triplet-subsequence/"}},{id:"post-151-reverse-words-in-a-string",title:"151. Reverse Words in a String",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/leetcode-reverse-words_in_a_string/"}},{id:"post-345-reverse-vowels-of-a-string",title:"345. Reverse Vowels of a String",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/leetcode-reserve-vowels/"}},{id:"post-1071-greatest-common-divisor-of-string",title:"1071. Greatest Common Divisor of String",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/leetcode-greatest-common-divisors-of-string/"}},{id:"post-605-can-place-flowers",title:"605. Can Place Flowers",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/leetcode-can_place_flowers/"}},{id:"post-1431-kids-with-the-greatest-number-of-candies",title:"1431. Kids With the Greatest Number of Candies",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/leetcode-1431.KidsWiththeGreatestNumberofCandies/"}},{id:"post-1768-merge-strings-alternately",title:"1768. Merge Strings Alternately",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/leetcode-1768-merge-strings-alternately/"}},{id:"post-nlp-text-processing-and-star-rating-analysis-application",title:"NLP Text Processing and Star Rating Analysis Application",description:"A practical guide to applying NLP techniques for analyzing text and predicting star ratings.",section:"Posts",handler:()=>{window.location.href="/blog/2024/nlp-starreview-aws-sagemaker-autopilot/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march &amp; april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_inline/"}},{id:"news-i-received-gpn-cyber-team-sc20-scholarship-2020-the-international-conference-for-high-performance-computing-networking-storage-and-analysis-virtual-conference-sponsored-by-nsf-oac-award-1925681",title:"I received GPN Cyber Team SC20 Scholarship 2020 The International Conference for High...",description:"",section:"News"},{id:"news-i-received-student-travel-grant-2021-vision-conference-washington-dc-usa-sponsored-by-bridges-international-usa",title:"I received Student Travel Grant 2021 Vision Conference, Washington DC, USA. Sponsored by...",description:"",section:"News"},{id:"news-i-received-the-usenix-s-student-travel-grant-2022-enigma-conference-santa-clara-usa-sponsored-by-usenix-the-advanced-computing-systems-association",title:"I received the USENIX\u2019s Student Travel Grant 2022 Enigma Conference, Santa Clara, USA....",description:"",section:"News"},{id:"news-i-served-as-a-session-chair-at-2022-informs-annual-meeting-indianapolis-usa",title:"I served as a Session Chair at 2022 INFORMS Annual Meeting, Indianapolis, USA....",description:"",section:"News"},{id:"news-i-has-been-named-a-future-faculty-fellow-2023-2024-by-the-institute-for-industrial-and-systems-engineers-iise",title:"I has been named a Future Faculty Fellow (2023-2024) by the Institute for...",description:"",section:"News"},{id:"news-i-served-as-a-session-chair-and-gave-a-talk-on-generative-model-at-2023-informs-annual-meeting-phoenix-usa",title:"I served as a Session Chair and gave a talk on generative model...",description:"",section:"News"},{id:"news-i-presented-my-work-smart-iot-system-for-cancer-undergoing-treatment-at-iise-annual-conference-montreal-canada",title:"I presented my work \u201cSmart IoT System for Cancer undergoing Treatment\u201d at IISE...",description:"",section:"News"},{id:"news-i-presented-my-work-at-2024-informs-security-conference-arlington-va-usa",title:"I presented my work at 2024 INFORMS Security Conference, Arlington, VA, USA.",description:"",section:"News"},{id:"projects-global-sales-analysis-dashboard",title:"Global Sales Analysis Dashboard",description:"This project visualizes global sales performance using Tableau. It highlights key metrics and trends to aid business decision-making.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-automated-defect-inspection-system-with-robotic-arm-and-deep-learning",title:"Automated Defect Inspection System with Robotic Arm and Deep Learning",description:"Developed an automated defect inspection system using a robotic arm, computer vision, and deep learning to efficiently detect and classify product defects on a conveyor belt.",section:"Projects",handler:()=>{window.location.href="/projects/Automated-Defect-Inspection-System-with-Robotic-Arm-and-Deep-Learning/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%71%75%6F%63%6E%68%39%31@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=yikSJwMAAAAJ","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/quocnh","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>